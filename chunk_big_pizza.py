import os
import chromadb
from chromadb.utils import embedding_functions
import fitz
import re
import json

# D√©sactive compl√®tement la t√©l√©m√©trie pour √©viter les erreurs
os.environ["CHROMA_ENABLE_TELEMETRY"] = "false"

# --- 1. Configuration ---
COLLECTION_NAME = "la_belle_pizza_collection"
EMBEDDING_MODEL = "nomic-embed-text:v1.5"

def load_and_chunk_pdf(file_path, chunk_size=1000, chunk_overlap=200):
    """
    Charge et d√©coupe le PDF du menu en chunks
    """
    print(f"Chargement du fichier : {file_path}")
    doc = fitz.open(file_path)
    text = ""
    for page in doc:
        text += page.get_text()

    print(f"Le document contient {len(text)} caract√®res.")

    # Nettoyage basique du texte
    text = re.sub(r'\s+', ' ', text)  # Normalise les espaces
    text = text.strip()

    print("D√©coupage du texte en chunks...")
    chunks = []
    
    # D√©coupage par sections du menu
    sections = ["ANTIPASTI", "INSALATA", "PIZZA", "PASTA", "RISOTTO", "DOLCI", "EXTRAS", "BOISSONS", "KIDS"]
    
    for i, section in enumerate(sections):
        start_idx = text.upper().find(section)
        if start_idx != -1:
            # Trouve la fin de cette section (d√©but de la suivante)
            end_idx = len(text)
            for next_section in sections[i+1:]:
                next_start = text.upper().find(next_section, start_idx + len(section))
                if next_start != -1:
                    end_idx = next_start
                    break
            
            section_text = text[start_idx:end_idx].strip()
            if section_text:
                chunks.append(f"Section {section}:\n{section_text}")
    
    # Si aucune structure d√©tect√©e, d√©coupage classique
    if not chunks:
        for i in range(0, len(text), chunk_size - chunk_overlap):
            chunk = text[i:i + chunk_size]
            if chunk.strip():
                chunks.append(chunk)

    print(f"{len(chunks)} chunks ont √©t√© cr√©√©s pour le menu.")
    return chunks

def load_allergenes_json(file_path):
    """
    Charge le fichier JSON des allerg√®nes et le pr√©pare pour l'indexation
    """
    print(f"Chargement du fichier JSON : {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    chunks = []
    
    # Chunk pour les informations g√©n√©rales
    general_info = f"""Informations allerg√®nes - Restaurant: {data['restaurant']}
Date de mise √† jour: {data['date_mise_a_jour']}
Avertissement: {data['avertissement']}"""
    chunks.append(general_info)
    
    # Chunk pour chaque cat√©gorie de produits
    for category, items in data['allergenes_par_produit'].items():
        if isinstance(items, dict):
            category_text = f"Allerg√®nes - Cat√©gorie {category}:\n"
            for item_name, allergenes in items.items():
                if isinstance(allergenes, list):
                    allergenes_str = ", ".join(allergenes)
                    category_text += f"- {item_name}: {allergenes_str}\n"
            chunks.append(category_text)
        elif isinstance(items, list):
            # Pour les items simples comme PAIN_CIABATTA
            allergenes_str = ", ".join(items)
            chunks.append(f"Allerg√®nes - {category}: {allergenes_str}")
    
    # Chunk pour les recherches par allerg√®ne
    search_info = "Recherche par allerg√®ne:\n"
    for allergen_type, info in data['recherche_par_allergene'].items():
        search_info += f"\n{allergen_type}:\n"
        if 'note' in info:
            search_info += f"Note: {info['note']}\n"
        if 'plats_potentiels' in info and info['plats_potentiels']:
            search_info += f"Plats possibles: {', '.join(info['plats_potentiels'])}\n"
        if 'plats_possibles' in info:
            search_info += f"Plats possibles: {', '.join(info['plats_possibles'])}\n"
        if 'plats' in info:
            search_info += f"Plats: {', '.join(info['plats'])}\n"
    
    chunks.append(search_info)
    
    print(f"{len(chunks)} chunks ont √©t√© cr√©√©s pour les allerg√®nes.")
    return chunks

def main():
    print("üöÄ Initialisation de ChromaDB...")
    # Cr√©e le client sans t√©l√©m√©trie
    client = chromadb.PersistentClient(path="./data/chroma_db")

    print("ü§ñ Initialisation de la fonction d'embedding via Ollama...")
    try:
        ollama_ef = embedding_functions.OllamaEmbeddingFunction(
            url="http://localhost:11434/api/embeddings",
            model_name=EMBEDDING_MODEL,
        )
    except Exception as e:
        print(f"‚ùå Erreur avec Ollama: {e}")
        print("V√©rifiez que Ollama est lanc√© et que le mod√®le est t√©l√©charg√©:")
        print(f"ollama pull {EMBEDDING_MODEL}")
        return

    print(f"üìÇ Cr√©ation ou chargement de la collection : {COLLECTION_NAME}")
    collection = client.get_or_create_collection(
        name=COLLECTION_NAME, 
        embedding_function=ollama_ef
    )

    # Traite le fichier PDF du menu
    menu_pdf_path = "data/pdf/Menu.pdf"
    if os.path.exists(menu_pdf_path):
        try:
            print("üìã Traitement du menu PDF...")
            menu_chunks = load_and_chunk_pdf(menu_pdf_path)
            
            if menu_chunks:
                print(f"üíæ Stockage des chunks du menu...")
                ids = [f"chunk_menu_{i}" for i in range(len(menu_chunks))]
                metadatas = [{"source": "Menu.pdf", "type": "menu"} for _ in range(len(menu_chunks))]
                
                collection.add(
                    documents=menu_chunks, 
                    ids=ids,
                    metadatas=metadatas
                )
                print(f"‚úÖ Menu trait√© avec succ√®s!")
            else:
                print(f"‚ö†Ô∏è  Aucun chunk cr√©√© pour le menu")
                
        except Exception as e:
            print(f"‚ùå Erreur lors du traitement du menu: {e}")
    else:
        print(f"‚ö†Ô∏è  Fichier menu non trouv√©: {menu_pdf_path}")

    # Traite le fichier JSON des allerg√®nes
    allergenes_json_path = "data/json/allergene.json"
    if os.path.exists(allergenes_json_path):
        try:
            print("üö® Traitement du fichier allerg√®nes JSON...")
            allergenes_chunks = load_allergenes_json(allergenes_json_path)
            
            if allergenes_chunks:
                print(f"üíæ Stockage des chunks des allerg√®nes...")
                ids = [f"chunk_allergenes_{i}" for i in range(len(allergenes_chunks))]
                metadatas = [{"source": "allergene.json", "type": "allergenes"} for _ in range(len(allergenes_chunks))]
                
                collection.add(
                    documents=allergenes_chunks, 
                    ids=ids,
                    metadatas=metadatas
                )
                print(f"‚úÖ Allerg√®nes trait√©s avec succ√®s!")
            else:
                print(f"‚ö†Ô∏è  Aucun chunk cr√©√© pour les allerg√®nes")
                
        except Exception as e:
            print(f"‚ùå Erreur lors du traitement des allerg√®nes: {e}")
    else:
        print(f"‚ö†Ô∏è  Fichier allerg√®nes non trouv√©: {allergenes_json_path}")

    print(f"\nüéâ Base de donn√©es vectorielle cr√©√©e avec succ√®s !")
    print(f"üìä Nombre total de documents stock√©s : {collection.count()}")

if __name__ == "__main__":
    main()